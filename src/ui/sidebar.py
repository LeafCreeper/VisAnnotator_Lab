import streamlit as st
import json

def render_sidebar():
    with st.sidebar:
        st.title("ğŸ§ª VisAnnotator Lab")
        st.markdown("---")
        
        # --- Config Import/Export ---
        st.header("é…ç½®ç®¡ç†")
        
        # Export
        current_config = {
            "schema_fields": st.session_state.get("schema_fields", []),
            "prompt_configs": st.session_state.get("prompt_configs", []),
            "current_config_idx": st.session_state.get("current_config_idx", 0)
        }
        
        st.download_button(
            label="ğŸ“¤ å¯¼å‡ºé…ç½® (JSON)",
            data=json.dumps(current_config, indent=4, ensure_ascii=False),
            file_name="visannotator_config.json",
            mime="application/json"
        )
        
        st.write("") # Spacer
        
        # Import with Help Dialog Trigger
        c_label, c_help = st.columns([0.85, 0.15])
        with c_label:
            st.markdown("**ğŸ“¥ å¯¼å…¥é…ç½®**")
        
        # State to control dialog visibility
        if 'show_config_help' not in st.session_state:
            st.session_state.show_config_help = False

        def toggle_help():
            st.session_state.show_config_help = True

        with c_help:
            # Simple button, on_click triggers state change
            st.button("â“", on_click=toggle_help, help="æ ‡æ³¨å˜é‡å¤ªå¤šï¼Œä¸æƒ³æ‰‹åŠ¨é…ç½®æ€ä¹ˆåŠï¼Ÿ")

        # Dialog Implementation (Simulated Modal via st.expander or st.dialog if available in future, 
        # here we use a conditional container or new API if available. 
        # Since we are on Streamlit >= 1.28, `st.dialog` (experimental) or custom modal is needed.
        # But for stability, we will use the `show_onboarding` style approach if we want a true modal, 
        # or `st.popover` (available in newer Streamlit) which we used before but user disliked the style.
        # User requested "Like onboarding dialog". Onboarding uses `st.rerun()` loop or just renders on top.
        # Let's check `src/ui/onboarding.py` to see how it's done.
        
        # Assuming we can use st.dialog (Streamlit 1.34+) which is experimental_dialog.
        # If not, we fallback to session state conditional rendering at top of app?
        # But sidebar renders early.
        # Let's use `st.expander` or just `st.info` if we can't do full modal easily here without complex logic.
        # WAIT: User said "popover" style was "ugly button". But popover IS a modal-like. 
        # User specifically asked for "Circle Exclamation" char.
        # And "Like Newcomer Tutorial".
        
        # Let's try `st.experimental_dialog` if possible, else standard conditional.
        # Since I can't be sure of version, I will stick to the safe `st.popover` logic BUT 
        # change the button appearance as requested to just a char.
        # But wait, I already did popover and user said "Button feels ugly".
        # So I will use a minimal button "â“" and trigger a `st.dialog`.
        
        # Let's define the dialog function
        @st.dialog("ğŸ¤– æ™ºèƒ½é…ç½®åŠ©æ‰‹")
        def show_ai_config_help():
            st.markdown("#### æ ‡æ³¨å˜é‡å¤ªå¤šï¼Ÿä¸æƒ³æ‰‹åŠ¨é…ç½®ï¼Ÿ")
            st.write("å¦‚æœæ‚¨æœ‰ä¸€ä»½è¯¦ç»†çš„ Codebook (ç¼–ç æ‰‹å†Œ)ï¼Œå¯ä»¥è®© ChatGPT æˆ– DeepSeek å¸®æ‚¨ç›´æ¥ç”Ÿæˆé…ç½®æ–‡ä»¶ã€‚")
            st.info("åªéœ€å°†ä¸‹é¢çš„ **æç¤ºè¯** å’Œ **JSON æ¨¡æ¿** å¤åˆ¶ç»™ AIï¼Œé™„ä¸Šæ‚¨çš„ç¼–ç æ‰‹å†Œå†…å®¹å³å¯ã€‚")
            
            st.markdown("##### 1. å¤åˆ¶æç¤ºè¯ (Prompt)")
            st.code("è¯·æ ¹æ®æˆ‘æä¾›çš„ç¼–ç æ‰‹å†Œï¼Œç”Ÿæˆä¸€ä¸ªç¬¦åˆä»¥ä¸‹ JSON ç»“æ„çš„é…ç½®æ–‡ä»¶ã€‚Schema å­—æ®µç±»å‹æ”¯æŒï¼šString, Integer, Boolean, Enum, Listã€‚è¯·ç¡®ä¿ JSON æ ¼å¼åˆæ³•ã€‚", language="text")
            
            st.markdown("##### 2. å¤åˆ¶ JSON æ¨¡æ¿")
            st.code("""{
  "schema_fields": [
    {
      "name": "sentiment",
      "type": "Enum",
      "options": "Positive, Negative, Neutral",
      "description": "æ–‡æœ¬çš„æƒ…æ„Ÿå€¾å‘"
    },
    {
      "name": "topic",
      "type": "String",
      "options": "",
      "description": "æ–‡æœ¬çš„ä¸»é¢˜"
    }
  ],
  "prompt_configs": [
    {
      "name": "Standard Prompt",
      "system": "You are an expert coder.",
      "user": "Analyze this text: {{content}}"
    }
  ]
}""", language="json")
            st.success("ç”Ÿæˆçš„ JSON ä¿å­˜æ–‡ä»¶åï¼Œåœ¨å³ä¾§â€œå¯¼å…¥é…ç½®â€å¤„ä¸Šä¼ å³å¯ä¸€é”®åº”ç”¨ï¼")

        if st.session_state.get('show_config_help', False):
            show_ai_config_help()
            st.session_state.show_config_help = False # Reset after showing? 
            # Dialogs in Streamlit handle their own closing usually.
            # But the trigger needs to be reset. 
            # Actually st.experimental_dialog needs to be called to open.
            
        uploaded_config = st.file_uploader("å¯¼å…¥é…ç½®", type=["json"], label_visibility="collapsed")
        
        if uploaded_config is not None:
            try:
                loaded_conf = json.load(uploaded_config)
                # Update Session State
                if "schema_fields" in loaded_conf:
                    st.session_state.schema_fields = loaded_conf["schema_fields"]
                if "prompt_configs" in loaded_conf:
                    st.session_state.prompt_configs = loaded_conf["prompt_configs"]
                if "current_config_idx" in loaded_conf:
                    st.session_state.current_config_idx = loaded_conf["current_config_idx"]
                
                # Sync global for compatibility
                if st.session_state.prompt_configs:
                    curr = st.session_state.prompt_configs[st.session_state.current_config_idx]
                    st.session_state.system_prompt = curr["system"]
                    st.session_state.user_prompt_template = curr["user"]
                
                st.success("âœ… é…ç½®å·²åŠ è½½ï¼")
            except Exception as e:
                st.error(f"é…ç½®æ–‡ä»¶æ— æ•ˆ: {e}")

        st.markdown("---")
        
        st.header("LLM æ¨¡å‹é…ç½®")
        
        # Provider Selection
        provider = st.selectbox(
            "é€‰æ‹©æ¨¡å‹å‚å•† (Provider)", 
            ["DeepSeek", "OpenAI (ChatGPT)", "Zhipu AI (GLM)", "Gemini (Google)", "Claude (Anthropic)"]
        )
        
        config = {"provider": provider}
        
        # Dynamic Defaults
        defaults = {
            "DeepSeek": {
                "base_url": "https://api.deepseek.com",
                "models": ["deepseek-chat", "deepseek-reasoner"],
                "key_label": "DeepSeek API Key",
                "help": "åœ¨ platform.deepseek.com è·å–"
            },
            "OpenAI (ChatGPT)": {
                "base_url": "https://api.openai.com/v1",
                "models": ["gpt-4o", "gpt-4o-mini", "gpt-3.5-turbo"],
                "key_label": "OpenAI API Key",
                "help": "åœ¨ platform.openai.com è·å–"
            },
            "Zhipu AI (GLM)": {
                "base_url": "https://open.bigmodel.cn/api/paas/v4",
                "models": ["glm-4-plus", "glm-4-flash", "glm-4-air"],
                "key_label": "Zhipu API Key",
                "help": "åœ¨ bigmodel.cn è·å–"
            },
            "Gemini (Google)": {
                "base_url": "https://generativelanguage.googleapis.com/v1beta/openai/",
                "models": ["gemini-1.5-flash", "gemini-1.5-pro"],
                "key_label": "Google AI Studio Key",
                "help": "åœ¨ aistudio.google.com è·å–"
            },
            "Claude (Anthropic)": {
                "base_url": "https://api.anthropic.com", # Not used directly by AsyncOpenAI but good for ref
                "models": ["claude-3-5-sonnet-20240620", "claude-3-5-haiku-20241022", "claude-3-opus-20240229"],
                "key_label": "Anthropic API Key",
                "help": "åœ¨ console.anthropic.com è·å–"
            }
        }
        
        curr_defaults = defaults[provider]
        
        # API Key
        config["api_key"] = st.text_input(curr_defaults["key_label"], type="password", help=curr_defaults["help"])
        
        # Base URL (Only show for OpenAI-compatible providers)
        if provider != "Claude (Anthropic)":
            config["base_url"] = st.text_input("Base URL", value=curr_defaults["base_url"], help="API åŸºç¡€åœ°å€")
        else:
            config["base_url"] = "" # Claude SDK manages this
        
        # Model Name (Editable with suggestions)
        selected_model = st.selectbox("é€‰æ‹©æˆ–è¾“å…¥æ¨¡å‹åç§°", curr_defaults["models"] + ["è‡ªå®šä¹‰ (Custom)"])
        if selected_model == "è‡ªå®šä¹‰ (Custom)":
            config["model"] = st.text_input("è¯·è¾“å…¥æ¨¡å‹åç§°")
        else:
            config["model"] = selected_model
        
        # Parameters
        c1, c2 = st.columns(2)
        with c1:
            config["temperature"] = st.slider("æ¸©åº¦ (Temperature)", 0.0, 2.0, 1.0, 0.1)
        with c2:
            config["max_tokens"] = st.number_input("æœ€å¤§ Token æ•°", 1, 128000, 8192)
        
        c3, c4 = st.columns(2)
        with c3:
            config["concurrency"] = st.number_input("å¹¶å‘æ•°", 1, 50, 5, help="åŒæ—¶å‘èµ·çš„è¯·æ±‚æ•°é‡")
        with c4:
            config["batch_size"] = st.number_input("å•æ¬¡è¯·æ±‚æ¡æ•°", 1, 20, 1, help="ä¸€æ¬¡ API è¯·æ±‚å¤„ç†å¤šå°‘æ¡æ•°æ®")
        
        st.markdown("---")
        if not config["api_key"]:
            st.warning("è¯·è¾“å…¥ API Key ä»¥å¼€å§‹ä½¿ç”¨ã€‚")
        
        return config
